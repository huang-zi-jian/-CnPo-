<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Layui</title>
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <link rel="stylesheet" href="../layui/css/layui.css"  media="all">
  <!-- 注意：如果你直接复制所有代码到本地，上述css路径需要改成你本地的 -->
</head>
<body>

<blockquote class="layui-elem-quote">
    <p style="color:teal; font-size: 20px; font-weight: 550;">数据集详情</p>
</blockquote>

<table class="layui-table" lay-even="" lay-skin="row">
  <colgroup>
    <col width="300">
    <col>
  </colgroup>

  <thead>
    <tr>
      <th>原始数据集名称</th>
      <th>CIFAR-10 python version 图片数据集</th>
    </tr> 
  </thead>
  <tbody>
    <tr>
      <td>数据介绍</td>
      <td>本身具有良好的标签 数据格式为：&lt;标签&gt; &lt;3072byte个像素&gt;（其中3*1024个rgb图）。该数据集共有60000张彩色图像，这些图像大小为32*32，分为10个类，每类6000张图。
        这里面有50000张用于训练，另外10000用于测试。</td>
    </tr>
    <tr>
      <td>数据来源</td>
      <td>http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</td>
    </tr>
    <tr>
      <td>文件类型</td>
      <td>tar.gz</td>
    </tr>
    <tr>
      <td>文件大小</td>
      <td>163MB</td>
    </tr>
    <tr>
      <td>加密后文件大小（5种加密算法）</td>
      <td>1.72G</td>
    </tr>
  </tbody>
</table>  

<table class="layui-table" lay-even="" lay-skin="row">
  <colgroup>
    <col width="300">
    <col>
  </colgroup>
  <thead>
    <tr>
      <th>原始数据集名称</th>
      <th>Caltech256  图片数据集</th>
    </tr> 
  </thead>
  <tbody>
    <tr>
      <td>数据介绍</td>
      <td>包含30607张图片，256类图片，每类图片最少有80张图片。照片大小不固定，
        每张照片都进行过挑选，因此可以认为是具有良好标签的数据</td>
    </tr>
    <tr>
      <td>数据来源</td>
      <td>http://www.vision.caltech.edu/Image_Datasets/Caltech256/256_ObjectCategories.tar</td>
    </tr>
    <tr>
      <td>文件类型</td>
      <td>tar</td>
    </tr>
    <tr>
      <td>文件大小</td>
      <td>1.2GB</td>
    </tr>
    <tr>
      <td>加密后文件大小（5种加密算法）</td>
      <td>8.84G</td>
    </tr>
  </tbody>
  </table>  

<table class="layui-table" lay-even="" lay-skin="row">
  <colgroup>
    <col width="300">
    <col>
  </colgroup>
    <thead>
      <tr>
        <th>原始数据集名称</th>
        <th>LibriSpeech ASR corpus</th>
      </tr> 
    </thead>
    <tbody>
      <tr>
        <td>数据介绍</td>
        <td>是一个包含大约1000小时的英语语音的大型语料库，
          它被分割并对齐，整理成每条10秒左右的、经过文本标注的音频文件。</td>
      </tr>
      <tr>
        <td>数据来源</td>
        <td>https://openslr.magicdatatech.com/resources/12/train-clean-100.tar.gz</td>
      </tr>
      <tr>
        <td>文件类型</td>
        <td>tar.gz</td>
      </tr>
      <tr>
        <td>文件大小</td>
        <td>6.3G</td>
      </tr>
      <tr>
        <td>加密后文件大小（5种加密算法）</td>
        <td>38.8G</td>
      </tr>
    </tbody>
</table>  


<table class="layui-table" lay-even="" lay-skin="row">
  <colgroup>
    <col width="300">
    <col>
  </colgroup>
  <thead>
    <tr>
      <th>原始数据集名称</th>
      <th>THUCNews</th>
    </tr> 
  </thead>
  <tbody>
    <tr>
      <td>数据介绍</td>
      <td>根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成均为纯文字的新闻文本，大小不固定这里我们
        选取了其中财经、股票、时政、体育四个类别中的568个文件进行数据集的制作，得到xx的密文数据。</td>
    </tr>
    <tr>
      <td>数据来源</td>
      <td>https://thunlp.oss-cn-qingdao.aliyuncs.com/THUCNews.zip</td>
    </tr>
    <tr>
      <td>文件类型</td>
      <td>zip</td>
    </tr>
    <tr>
      <td>文件大小</td>
      <td>15.3MB</td>
    </tr>
    <tr>
      <td>加密后文件大小（5种加密算法）</td>
      <td>125MB</td>
    </tr>
  </tbody>
</table>  

<blockquote class="layui-elem-quote" style="margin-top: 80px;">
    <p style="color:teal; font-size: 20px; font-weight: 550;">概念层次</p>
</blockquote>

<table class="layui-table" lay-even="" lay-skin="row">
  <colgroup>
    <col width="200">
    <col>
  </colgroup>
  
  <thead>
    <tr>
      <th>领域场景</th>
      <th>未指定</th>
    </tr> 
  </thead>
  <tbody>
    <tr>
      <td>领域问题</td>
      <td>未指定</td>
    </tr>
    <tr>
      <td>领域应用</td>
      <td>未指定</td>
    </tr>
    <tr>
      <td>领域案例</td>
      <td>未指定</td>
    </tr>
  </tbody>
</table>  

<script src="../layui/layui.js" charset="utf-8"></script>
<!-- 注意：如果你直接复制所有代码到本地，上述js路径需要改成你本地的 -->
</body>
</html>